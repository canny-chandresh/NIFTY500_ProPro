name: Hourly / Daily / Weekly / Monthly

on:
  workflow_dispatch: {}
  schedule:
    # Run every 30 minutes on weekdays (Mon-Fri). We'll self-gate by IST time in code.
    - cron: "*/30 * * * 1-5"
    # Saturday weekly window around 12:30 IST (07:00 UTC). We'll self-gate for weekly.
    - cron: "0 7 * * 6"

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show tree (sanity)
        run: |
          echo "== repo root ==" && ls -la
          echo "== src ==" && ls -la src || true
          echo "== workflows ==" && ls -la .github/workflows || true
          echo "== datalake ==" && ls -la datalake || true
          echo "== reports ==" && ls -la reports || true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          # extras we rely on
          pip install pandas pyarrow yfinance ta graphviz || true

      - name: Ensure datalake exists (optional bootstrap unzip)
        run: |
          if [ ! -d "datalake" ]; then
            echo "No datalake/ present."
            if [ -f "datalake-bootstrap.zip" ]; then
              echo "Unzipping datalake-bootstrap.zip …"
              sudo apt-get update -y >/dev/null 2>&1 || true
              sudo apt-get install -y unzip >/dev/null 2>&1 || true
              unzip -o datalake-bootstrap.zip -d . || true
              # If zipped inside a folder, flatten:
              if [ -d "NIFTY500_ProPro/datalake" ]; then
                mv NIFTY500_ProPro/datalake ./ && rm -rf NIFTY500_ProPro
              fi
            else
              echo "No bootstrap zip; proceeding. First runs may fetch/update gradually."
            fi
          else
            echo "datalake/ exists."
          fi
          mkdir -p reports/metrics reports/html models

      - name: Main orchestrator (pre-open / intraday / 15:15 / EOD / weekly / monthly)
        env:
          TG_BOT_TOKEN: ${{ secrets.TG_BOT_TOKEN }}
          TG_CHAT_ID:  ${{ secrets.TG_CHAT_ID }}
        run: |
          python - <<'PY'
          import os, sys, traceback, json, datetime as dt
          from zoneinfo import ZoneInfo

          # Import path
          sys.path.append("src")

          # Helpers
          def now_ist():
              return dt.datetime.now(ZoneInfo("Asia/Kolkata"))

          def is_weekend_ist(t: dt.datetime):
              # Saturday=5, Sunday=6
              return t.weekday() >= 5

          # Gating windows (IST)
          t = now_ist()
          hhmm = t.strftime("%H:%M")
          dow = t.weekday()  # 0=Mon, 6=Sun
          is_bday = (dow <= 4)  # Mon-Fri; (holiday logic can be added via src/holidays.py if you have it)

          # Flags
          do_preopen = is_bday and ("08:30" <= hhmm <= "09:10")
          do_intraday = is_bday and ("09:30" <= hhmm <= "15:15")
          do_315 = is_bday and (hhmm >= "15:15" and hhmm <= "15:20")
          do_eod = is_bday and (hhmm >= "17:00" and hhmm <= "17:10")
          do_weekly = (dow == 5) and ("12:15" <= hhmm <= "12:45")  # Saturday ~12:30 IST
          # Month-end check: if tomorrow month != today month and after 17:00 IST
          tomorrow = t + dt.timedelta(days=1)
          is_month_end = (t.month != tomorrow.month)
          do_monthly = is_month_end and (hhmm >= "17:00" and hhmm <= "17:30")

          print(f"[IST] Now={t.isoformat()}  hh:mm={hhmm}  DoW={dow}")
          print(json.dumps({
              "preopen": do_preopen, "intraday": do_intraday, "at_3_15": do_315,
              "eod": do_eod, "weekly": do_weekly, "monthly": do_monthly
          }, indent=2))

          # Import modules defensively
          try:
              from entrypoints import daily_update, eod_task, periodic_reports_task, after_run_housekeeping
          except Exception as e:
              print("Entry import error:", e)
              traceback.print_exc()
              daily_update = eod_task = periodic_reports_task = after_run_housekeeping = None

          # Pre-open warm-up: capture GIFT, VIX, news pulse, update regime
          if do_preopen:
              print("== PRE-OPEN WARM-UP ==")
              try:
                  if daily_update:
                      daily_update(preopen=True)   # your function can ignore kw if not defined
              except Exception as e:
                  print("preopen error:", e); traceback.print_exc()

          # Intraday hourly: run AI (AUTO + conditional ALGO)
          if do_intraday or do_315:
              print("== INTRADAY / AI ==")
              try:
                  from pipeline_ai import run_auto_and_algo_sessions
                  a,b = run_auto_and_algo_sessions()
                  print(f"AUTO orders: {a}, ALGO orders: {b}")
              except Exception as e:
                  print("pipeline_ai error:", e); traceback.print_exc()
              # After each intraday block, run housekeeping (drift checks, etc.)
              try:
                  if after_run_housekeeping:
                      after_run_housekeeping()
              except Exception as e:
                  print("housekeeping error:", e); traceback.print_exc()

          # 3:15 picks: the same intraday block above already runs at this time;
          # your Telegram 3:15 send is handled inside your reporting/notify functions.
          # If you prefer an explicit ensure-send hook, you can add one here.

          # EOD compile (5:00 PM IST): send reports and refresh metrics
          if do_eod:
              print("== EOD TASKS ==")
              try:
                  if eod_task:
                      eod_task()
              except Exception as e:
                  print("eod_task error:", e); traceback.print_exc()
              try:
                  if periodic_reports_task:
                      periodic_reports_task()  # may roll daily aggregates
              except Exception as e:
                  print("periodic_reports_task error:", e); traceback.print_exc()
              try:
                  if after_run_housekeeping:
                      after_run_housekeeping()
              except Exception as e:
                  print("housekeeping(EOD) error:", e); traceback.print_exc()

          # Weekly (Saturday) roll-up
          if do_weekly:
              print("== WEEKLY REPORT ==")
              try:
                  if periodic_reports_task:
                      periodic_reports_task(kind="weekly")
              except Exception as e:
                  print("weekly error:", e); traceback.print_exc()

          # Month-end roll-up
          if do_monthly:
              print("== MONTHLY REPORT ==")
              try:
                  if periodic_reports_task:
                      periodic_reports_task(kind="monthly")
              except Exception as e:
                  print("monthly error:", e); traceback.print_exc()

          # Always: print AI status to logs for visibility
          try:
              from status_probe import print_status
              print_status()
          except Exception:
              pass

          # Optional: Telegram alert if AI is suspended
          try:
              from alerts import alert_if_suspended
              alert_if_suspended()
          except Exception:
              pass

          # Never hard-fail the job; we want schedules to continue even if one block errs
          PY

      - name: Bundle reports (if any) as artifact
        if: always()
        run: |
          mkdir -p out_bundle
          # common report outputs — adjust paths if your repo differs
          cp -r reports out_bundle/reports || true
          cp -r datalake out_bundle/datalake_snapshot || true
          tar -czf reports_bundle.tgz -C out_bundle .
          echo "Bundle created: reports_bundle.tgz"
          ls -la reports_bundle.tgz || true

      - name: Upload artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: reports_bundle
          path: reports_bundle.tgz
          if-no-files-found: ignore
